{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 22)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 22 columns):\n",
      "ind               41188 non-null int64\n",
      "age               41188 non-null int64\n",
      "job               40858 non-null object\n",
      "marital           41108 non-null object\n",
      "education         39457 non-null object\n",
      "default           32591 non-null object\n",
      "housing           40198 non-null object\n",
      "loan              40198 non-null object\n",
      "contact           41188 non-null object\n",
      "month             41188 non-null object\n",
      "day_of_week       41188 non-null object\n",
      "duration          41188 non-null int64\n",
      "campaign          41188 non-null int64\n",
      "pdays             41188 non-null int64\n",
      "previous          41188 non-null int64\n",
      "poutcome          5625 non-null object\n",
      "emp.var.rate      41188 non-null float64\n",
      "cons.price.idx    41188 non-null float64\n",
      "cons.conf.idx     41188 non-null float64\n",
      "euribor3m         41188 non-null float64\n",
      "nr.employed       41188 non-null float64\n",
      "y                 41188 non-null object\n",
      "dtypes: float64(5), int64(6), object(11)\n",
      "memory usage: 6.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\",sep=\",\")\n",
    "print(data.shape)\n",
    "print data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop observations with missing data\n",
    "data[\"poutcome\"]=data[\"poutcome\"].fillna(\"nonexistent\") # most value of \"poutcome\" are missing, keep them\n",
    "data=data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pre Condition: One Hot encode\n",
    "def one_hot_encode(data,column_name,index_name):\n",
    "    n = data.shape[0] #length of columns \n",
    "    binary_data = pd.DataFrame() #new dataframe to store cleaned data\n",
    "    old_row = data[column_name]\n",
    "    UniqueVal=[]\n",
    "    for elem in old_row:       \n",
    "        if not elem in UniqueVal:\n",
    "            UniqueVal.append(elem)\n",
    "    #creates new columns out of entries of old column\n",
    "    for new_col in UniqueVal:        \n",
    "        if new_col==\"nonexistent\":\n",
    "            #print (\"poutcome.\"+new_col)\n",
    "            binary_data[\"poutcome.\"+new_col] = (old_row==new_col)+0.0\n",
    "        else:\n",
    "            binary_data[new_col] = (old_row==new_col)+0.0\n",
    "    binary_data[index_name]=data[index_name]\n",
    "    return binary_data\n",
    "\n",
    "def binary_encode(data, column_name,index_name): # name \"yes\" as \"1\"\n",
    "    n = data.shape[0] #length of columns \n",
    "    binary_data = pd.DataFrame() #new dataframe to store cleaned data\n",
    "    old_row = data[column_name]\n",
    "    UniqueVal=[\"yes\",\"no\"]\n",
    "    #creates new columns out of entries of old column\n",
    "    binary_data[column_name] = (old_row==\"yes\")+0.0\n",
    "    binary_data[index_name]=data[index_name]\n",
    "    return binary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean data\n",
    "categorical_multi = [\"job\",\"marital\",\"education\",\"contact\",\"month\",\"day_of_week\",\"poutcome\"]\n",
    "categorical_binary=[\"default\",\"housing\",\"loan\",\"y\"]\n",
    "categorical_num=[\"ind\",\"age\",\"duration\",\"campaign\",\"previous\",\"emp.var.rate\",\"cons.price.idx\",\"cons.conf.idx\",\"euribor3m\",\"nr.employed\"]#,\"pdays\"\n",
    "flag=0\n",
    "for col in categorical_multi:\n",
    "    if flag==0:\n",
    "        clean_data= one_hot_encode(data,col,\"ind\")\n",
    "        flag+=1        \n",
    "    clean_data=pd.merge(clean_data,one_hot_encode(data,col,\"ind\"),how='left')\n",
    "    \n",
    "for col in categorical_binary:\n",
    "    clean_data=pd.merge(clean_data,binary_encode(data,col,\"ind\"),how='left')\n",
    "                   \n",
    "clean_data=pd.merge(clean_data,data[categorical_num])\n",
    "clean_data=clean_data.drop(\"ind\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24391, 52)\n"
     ]
    }
   ],
   "source": [
    "## data for tree models(without normalization)\n",
    "data_DT=clean_data\n",
    "\n",
    "## divide dataset into traininng(0.8),testing set(0.2)\n",
    "\n",
    "testing_set,training_set= train_test_split(data_DT, test_size=0.8)\n",
    "y_testing_DT=testing_set[\"y\"]\n",
    "x_testing_DT=testing_set.drop(\"y\",axis=1)\n",
    "y_training_DT=training_set[\"y\"]\n",
    "x_training_DT=training_set.drop(\"y\",axis=1)\n",
    "#drop duration\n",
    "x_training_DT=x_training_DT.drop(\"duration\",axis=1)\n",
    "x_testing_DT=x_testing_DT.drop(\"duration\",axis=1)\n",
    "print x_training_DT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "categorical_num=[\"age\",\"duration\",\"campaign\",\"previous\",\"emp.var.rate\",\"cons.price.idx\",\"cons.conf.idx\",\"euribor3m\",\"nr.employed\"]#pdays\n",
    "for elem in categorical_num:\n",
    "    clean_data[elem]=(clean_data[elem]-clean_data[elem].mean())/clean_data[elem].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return cleaned data \n",
    "clean_data.to_csv(\"clean_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24391, 52)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housemaid</th>\n",
       "      <th>services</th>\n",
       "      <th>admin.</th>\n",
       "      <th>technician</th>\n",
       "      <th>blue-collar</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>retired</th>\n",
       "      <th>entrepreneur</th>\n",
       "      <th>management</th>\n",
       "      <th>student</th>\n",
       "      <th>...</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480957</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786652</td>\n",
       "      <td>0.401641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.099677</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.787777</td>\n",
       "      <td>0.401641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.293221</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>0.727466</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.877437</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.401641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21009</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577730</td>\n",
       "      <td>-0.191699</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>-1.073330</td>\n",
       "      <td>-0.765854</td>\n",
       "      <td>-1.356734</td>\n",
       "      <td>-1.156258</td>\n",
       "      <td>-0.821115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.293221</td>\n",
       "      <td>-0.559326</td>\n",
       "      <td>-0.37161</td>\n",
       "      <td>0.913755</td>\n",
       "      <td>0.674250</td>\n",
       "      <td>-0.438010</td>\n",
       "      <td>0.844045</td>\n",
       "      <td>0.895268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       housemaid  services  admin.  technician  blue-collar  unemployed  \\\n",
       "3021         0.0       0.0     0.0         1.0          0.0         0.0   \n",
       "4429         0.0       1.0     0.0         0.0          0.0         0.0   \n",
       "3499         0.0       0.0     0.0         1.0          0.0         0.0   \n",
       "21009        0.0       0.0     0.0         0.0          1.0         0.0   \n",
       "7995         0.0       0.0     0.0         1.0          0.0         0.0   \n",
       "\n",
       "       retired  entrepreneur  management  student     ...       housing  loan  \\\n",
       "3021       0.0           0.0         0.0      0.0     ...           0.0   0.0   \n",
       "4429       0.0           0.0         0.0      0.0     ...           1.0   0.0   \n",
       "3499       0.0           0.0         0.0      0.0     ...           1.0   0.0   \n",
       "21009      0.0           0.0         0.0      0.0     ...           1.0   0.0   \n",
       "7995       0.0           0.0         0.0      0.0     ...           1.0   0.0   \n",
       "\n",
       "            age  campaign  previous  emp.var.rate  cons.price.idx  \\\n",
       "3021   0.480957 -0.559326  -0.37161      0.727466        0.804082   \n",
       "4429  -0.099677 -0.559326  -0.37161      0.727466        0.804082   \n",
       "3499  -0.293221 -0.559326  -0.37161      0.727466        0.804082   \n",
       "21009  0.577730 -0.191699  -0.37161     -1.073330       -0.765854   \n",
       "7995  -0.293221 -0.559326  -0.37161      0.913755        0.674250   \n",
       "\n",
       "       cons.conf.idx  euribor3m  nr.employed  \n",
       "3021        0.877437   0.786652     0.401641  \n",
       "4429        0.877437   0.787777     0.401641  \n",
       "3499        0.877437   0.786089     0.401641  \n",
       "21009      -1.356734  -1.156258    -0.821115  \n",
       "7995       -0.438010   0.844045     0.895268  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## divide dataset into traininng(0.8),testing set(0.2)\n",
    "\n",
    "testing_set,training_set= train_test_split(clean_data, test_size=0.8)\n",
    "y_testing=testing_set[\"y\"]\n",
    "x_testing=testing_set.drop(\"y\",axis=1)\n",
    "y_training=training_set[\"y\"]\n",
    "x_training=training_set.drop(\"y\",axis=1)\n",
    "#drop duration\n",
    "x_training=x_training.drop(\"duration\",axis=1)\n",
    "x_testing=x_testing.drop(\"duration\",axis=1)\n",
    "print x_training.shape\n",
    "x_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_Lasso:\n",
      "Lambda= 0.1 \n",
      "accuracy= 0.0421884445936\n"
     ]
    }
   ],
   "source": [
    "# Fit lasso regression model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "model_select=np.zeros((20,2))\n",
    "tmp=0\n",
    "lamda=0\n",
    "\n",
    "for i in np.linspace(1,20,20):\n",
    "    clf = linear_model.Lasso(alpha=i/10.0)#0.1-2.0\n",
    "    model_select[int(i-1),0]=i/10.0\n",
    "    model_select[int(i-1),1]=np.mean(cross_val_score(clf,x_training,y_training,cv=10))\n",
    "    if model_select[int(i-1),1]>tmp:\n",
    "        tmp= model_select[int(i-1),1]\n",
    "        lamda=i/10.0\n",
    "    \n",
    "print \"Best_Lasso:\\nLambda=\",lamda,\"\\naccuracy=\",tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.          0.         -0.         -0.          0.          0.\n",
      " -0.         -0.          0.         -0.         -0.          0.         -0.\n",
      "  0.         -0.         -0.         -0.         -0.          0.          0.\n",
      " -0.          0.         -0.          0.         -0.          0.          0.\n",
      " -0.          0.          0.          0.          0.         -0.          0.\n",
      "  0.          0.         -0.         -0.          0.          0.         -0.\n",
      "  0.         -0.          0.         -0.          0.         -0.         -0.\n",
      "  0.         -0.         -0.02220434]\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(x_training,y_training)\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Model is not suitable to be applied on this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training accuracy: ', 0.88885244557418719)\n",
      "Best_Logistic:\n",
      "Lambda= 1.8 \n",
      "accuracy= 0.888319160391\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression model\n",
    "model = LogisticRegression(penalty='l1', C=1, multi_class='ovr')\n",
    "model.fit(x_training, y_training)\n",
    "print(\"Training accuracy: \", model.score(x_training, y_training))\n",
    "model_select=np.zeros((20,2))\n",
    "tmp=0\n",
    "lamda=0\n",
    "for i in np.linspace(1,20,20):\n",
    "    clf = LogisticRegression(penalty='l1', C=i/10.0, multi_class='ovr')#0.1-2.0\n",
    "    model_select[int(i-1),0]=i/10.0\n",
    "    model_select[int(i-1),1]=np.mean(cross_val_score(clf,x_training,y_training,cv=10))\n",
    "    if model_select[int(i-1),1]>tmp:\n",
    "        tmp= model_select[int(i-1),1]\n",
    "        lamda=i/10.0\n",
    "print \"Best_Logistic:\\nLambda=\",lamda,\"\\naccuracy=\",tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[ 0.         -0.12335421  0.00543509  0.         -0.14532764  0.\n",
      "   0.16022173  0.          0.          0.11516578  0.         -0.02527353\n",
      "   0.         -0.02333491 -0.01359553  0.          0.          0.          0.\n",
      "   0.05200062  0.         -0.63516874  0.         -0.5810577  -0.27313616\n",
      "   0.          0.03518305  0.         -0.39658506  0.          0.9717043\n",
      "   0.         -0.09230158 -0.32026454  0.          0.07493433  0.\n",
      "  -0.12437032 -0.95906464 -1.43608555  0.26066877  0.         -0.03596629\n",
      "   0.          0.         -0.11496395  0.01425905 -1.21837461  0.66550766\n",
      "   0.12866684  0.          0.        ]]\n",
      "['housemaid' 'services' 'admin.' 'technician' 'blue-collar' 'unemployed'\n",
      " 'retired' 'entrepreneur' 'management' 'student' 'self-employed' 'married'\n",
      " 'single' 'divorced' 'basic.4y' 'high.school' 'basic.6y'\n",
      " 'professional.course' 'basic.9y' 'university.degree' 'illiterate'\n",
      " 'telephone' 'cellular' 'may' 'jun' 'jul' 'aug' 'oct' 'nov' 'dec' 'mar'\n",
      " 'apr' 'sep' 'mon' 'tue' 'wed' 'thu' 'fri' 'poutcome.nonexistent' 'failure'\n",
      " 'success' 'default' 'housing' 'loan' 'age' 'campaign' 'previous'\n",
      " 'emp.var.rate' 'cons.price.idx' 'cons.conf.idx' 'euribor3m' 'nr.employed']\n"
     ]
    }
   ],
   "source": [
    "#  Logistic Regression Model (find unefficient features)\n",
    "model = LogisticRegression(penalty='l1', C=0.1, multi_class='ovr')\n",
    "model.fit(x_training, y_training)\n",
    "print \"Coefficients:\", model.coef_\n",
    "print x_training.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the result from best Logistic Model, some features are of low correlation with classification. Thus, we prefer to remove them form the model, Such as 'euribor3m', 'nr.employed' and so on. Though the coefficents of some of dummy variables (first 41 features in the list) are also 0, we cannot remove them, because they are generated by one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.887950473535\n",
      "Coefficients: [[ 0.         -0.12366751  0.00538798  0.         -0.14561966  0.\n",
      "   0.16007952  0.          0.          0.11482946  0.         -0.02561143\n",
      "   0.         -0.02350662 -0.01353623  0.          0.          0.          0.\n",
      "   0.05173809  0.         -0.63532375  0.         -0.58086062 -0.2732672\n",
      "   0.          0.03523139  0.         -0.396425    0.          0.97167669\n",
      "   0.         -0.09257061 -0.32035795  0.          0.07477912  0.\n",
      "  -0.12456011 -0.66301783 -1.13952995  0.55737815 -0.03618094 -0.11493228\n",
      "   0.01406197 -1.21850775  0.66575119  0.12872286]]\n",
      "['housemaid' 'services' 'admin.' 'technician' 'blue-collar' 'unemployed'\n",
      " 'retired' 'entrepreneur' 'management' 'student' 'self-employed' 'married'\n",
      " 'single' 'divorced' 'basic.4y' 'high.school' 'basic.6y'\n",
      " 'professional.course' 'basic.9y' 'university.degree' 'illiterate'\n",
      " 'telephone' 'cellular' 'may' 'jun' 'jul' 'aug' 'oct' 'nov' 'dec' 'mar'\n",
      " 'apr' 'sep' 'mon' 'tue' 'wed' 'thu' 'fri' 'poutcome.nonexistent' 'failure'\n",
      " 'success' 'housing' 'campaign' 'previous' 'emp.var.rate' 'cons.price.idx'\n",
      " 'cons.conf.idx']\n",
      "('Testing accuracy: ', 0.89158602591438407)\n"
     ]
    }
   ],
   "source": [
    "# Test Logistic Regression Model (drop 'euribor3m', 'nr.employed',...)\n",
    "x_training_ed=x_training.drop([\"euribor3m\",\"nr.employed\",\"loan\", 'age','default'],axis=1)\n",
    "model = LogisticRegression(penalty='l1', C=0.1, multi_class='ovr')\n",
    "model.fit(x_training_ed, y_training)\n",
    "print \"Training Accuracy:\", model.score(x_training_ed, y_training)\n",
    "print \"Coefficients:\", model.coef_\n",
    "print x_training_ed.columns.values\n",
    "# test the model\n",
    "x_testing_ed=x_testing.drop([\"euribor3m\",\"nr.employed\",\"loan\", 'age','default'],axis=1)\n",
    "print [model.predict(x_testing_ed) y_testing]\n",
    "print(\"Testing accuracy: \", model.score(x_testing_ed, y_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though we discard some of the features and fit the model again, the accuracy of the model is stable (testing accuracy is 0.89), which justifies our revision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_SVM:\n",
      "Lambda= 0.6 \n",
      "accuracy= 0.88483463847\n"
     ]
    }
   ],
   "source": [
    "# SVM cross-validation\n",
    "from sklearn import svm\n",
    "model_select=np.zeros((5,2))\n",
    "tmp=0\n",
    "lamda=0\n",
    "for i in np.linspace(1,5,5):\n",
    "    clf = svm.SVC(kernel='linear', C=i*0.6)#choose penalty parameter within 0.1-3.0\n",
    "    model_select[int(i-1),0]=i*0.6\n",
    "    model_select[int(i-1),1]=np.mean(cross_val_score(clf,x_training,y_training,cv=4))\n",
    "    if model_select[int(i-1),1]>tmp:\n",
    "        tmp= model_select[int(i-1),1]\n",
    "        lamda=i*0.6\n",
    "print \"Best_SVM:\\nLambda=\",lamda,\"\\naccuracy=\",tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Testing accuracy: ', 0.88797769394784321)\n"
     ]
    }
   ],
   "source": [
    "# Test SVM Model\n",
    "model = svm.SVC(kernel='linear', C=0.6)\n",
    "model.fit(x_training, y_training)\n",
    "print(\"Testing accuracy: \", model.score(x_testing, y_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training accuracy: ', 0.9338690500594482)\n",
      "Best_DT:\n",
      "max_depth= 20 \n",
      "accuracy= 0.967078020581\n"
     ]
    }
   ],
   "source": [
    "# Fit a single decision tree\n",
    "model_select=np.zeros((16,2))\n",
    "tmp=0\n",
    "lamda=0\n",
    "\n",
    "print(\"Training accuracy: \", model.score(x_training, y_training))\n",
    "for i in np.linspace(5,20,16):#check max depth from 5-20\n",
    "    model = DecisionTreeClassifier(max_features=None, max_depth=int(i))#0.1-2.0\n",
    "    model.fit(x_training_DT, y_training_DT)\n",
    "    model_select[int(i-5),0]=int(i)\n",
    "    model_select[int(i-5),1]=model.score(x_training_DT, y_training_DT)\n",
    "    if model_select[int(i-5),1]>tmp:\n",
    "        tmp= model_select[int(i-5),1]\n",
    "        max_depth=int(i)\n",
    "print \"Best_DT:\\nmax_depth=\",max_depth,\"\\naccuracy=\",tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DT = DecisionTreeClassifier(max_features=None, max_depth=5)\n",
    "model_DT.fit(x_training_DT, y_training_DT)\n",
    "print(\"Training accuracy: \", model_DT.score(x_training_DT, y_training_DT))\n",
    "print(\"Testing accuracy: \", model_DT.score(x_testing_DT, y_testing_DT))\n",
    "\n",
    "\n",
    "from IPython.display import Image \n",
    "import graphviz \n",
    "from sklearn import tree\n",
    "Feature_names=['housemaid','services','admin.','technician','blue-collar','unemployed','retired','entrepreneur','management','student','self-employed','married','single','divorced','basic.4y','high.school','basic.6y'\n",
    ",'professional.course','basic.9y','university.degree','illiterate','telephone','cellular','may','jun','jul','aug','oct','nov','dec','mar','apr','sep','mon','tue','wed','thu','fri','poutcome.nonexistent','failure'\n",
    ",'success','default','housing','loan','age','campaign','previous','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']\n",
    "Class_names=['0','1']\n",
    "dot_data = tree.export_graphviz(model_DT, out_file=None,feature_names=Feature_names,class_names=Class_names,filled=True, rounded=True,special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training accuracy: ', 0.97015292525931696)\n",
      "('Testing accuracy: ', 0.84320157454485811)\n"
     ]
    }
   ],
   "source": [
    "model_DT = DecisionTreeClassifier(max_features=None, max_depth=20)\n",
    "model_DT.fit(x_training_DT, y_training_DT)\n",
    "print(\"Training accuracy: \", model_DT.score(x_training_DT, y_training_DT))\n",
    "print(\"Testing accuracy: \", model_DT.score(x_testing_DT, y_testing_DT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training accuracy: ', 0.99967202361429974)\n"
     ]
    }
   ],
   "source": [
    "base_model = DecisionTreeClassifier(max_features=None, max_depth=20)\n",
    "model = BaggingClassifier(base_estimator=base_model, n_estimators=50)\n",
    "model.fit(x_training, y_training)\n",
    "print(\"Training accuracy: \", model.score(x_training, y_training))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training accuracy: ', 0.95715632815382723)\n",
      "('Testing accuracy: ', 0.87846481876332627)\n"
     ]
    }
   ],
   "source": [
    "# Fit random forest\n",
    "modelrf = RandomForestClassifier(n_estimators=10, max_depth=20, max_features='auto')\n",
    "modelrf.fit(x_training_DT, y_training_DT)\n",
    "print(\"Training accuracy: \", modelrf.score(x_training_DT, y_training_DT))\n",
    "print(\"Testing accuracy: \", modelrf.score(x_testing_DT, y_testing_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training accuracy: ', 0.99401418556024768)\n",
      "('Testing accuracy: ', 0.84812202722650487)\n"
     ]
    }
   ],
   "source": [
    "# Fit boosted model\n",
    "base_model = DecisionTreeClassifier(max_features='auto', max_depth=30)\n",
    "#base_model = LogisticRegression(penalty='l2', C=10, multi_class='ovr')\n",
    "model = AdaBoostClassifier(base_estimator=base_model, n_estimators=10)\n",
    "model.fit(x_training_DT, y_training_DT)\n",
    "print(\"Training accuracy: \", model.score(x_training_DT, y_training_DT))\n",
    "print(\"Testing accuracy: \", model.score(x_testing_DT, y_testing_DT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
